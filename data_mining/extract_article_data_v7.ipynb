{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: make a map of literature on a certain topic where papers are individual nodes and two nodes are connected when a paper cites another. The most highly cited papers in the field will be prominent hubs, with satelite literature arounud them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data to scrape: \n",
    "- NIH PMID\n",
    "- Title\n",
    "- List of PMID of papers current paper cites\n",
    "- Total number of citations of paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root of graph is the oldest or most highly cited seminal paper\n",
    "Root connects to 3 most highly cited paper that the root cites\n",
    "The cycle continues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website to get pubmed urls for papers cited by current paper or cited in current paper\n",
    " https://www.ncbi.nlm.nih.gov/pmc/tools/cites-citedby/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea of how to do this\n",
    "\n",
    "collect sample of pubmed IDs of a given topic (say 1000 papers)\n",
    "\n",
    "find out which articles are cited by initial 1000 papers\n",
    "\n",
    "create dataframe where the columns are: 'article name' 'article id' 'global citations' 'citations within sample'\n",
    "\n",
    "arrange rows of data frame with the articles with the most citations in the sample at the top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pubmed data for 100 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    Entrez.email = 'cepeders@ncsu.edu'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='relevance', \n",
    "                            retmax='1000',           # number of articles pulled at once\n",
    "                            retmode='xml', \n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    #ids = ','.join(id_list)\n",
    "    Entrez.email = 'cepeders@ncsu.edu'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=id_list)\n",
    "    results = Entrez.read(handle)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate search for given term\n",
    "\n",
    "results = search('nucleus accumbens')\n",
    "\n",
    "id_list = results['IdList']\n",
    "\n",
    "#print(id_list)\n",
    "print(len(id_list))         # number of PMIDs in list\n",
    "print(len(set(id_list)))    # number of unique PMIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary key for each article's PMID, and append values of PMIDs that are cited by the key PMID\n",
    "\n",
    "cite_dict = {}\n",
    "\n",
    "for ID in id_list:\n",
    "    \n",
    "    cite_dict[ID] = []\n",
    "    \n",
    "    paper = fetch_details(ID)\n",
    "    \n",
    "    # get list of reference PMIDs for current article\n",
    "    citation_id = int(ID)\n",
    "    \n",
    "    # values = PMID of articles that cite current article\n",
    "    #response = requests.get('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?' +\n",
    "    #            'dbfrom=pubmed&linkname=pubmed_pubmed_citedin&id={citation_id}'.format(citation_id=citation_id))\n",
    "    \n",
    "    # values = PMID of articles that are cited by the current article\n",
    "    response = requests.get('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?' + \n",
    "                'dbfrom=pubmed&linkname=pubmed_pubmed_refs&id={citation_id}'.format(citation_id=citation_id))\n",
    "    \n",
    "    time.sleep(1)  # delays url request for n seconds\n",
    "    \n",
    "    soup = BeautifulSoup(response.text)\n",
    "    refs = soup.findAll('id')\n",
    "    refs = list(refs)\n",
    "    refs = refs[1:]   # first ref id is the paper itself (we should exclude)\n",
    "    \n",
    "    for k,ele in enumerate(refs):\n",
    "    \n",
    "        ele = str(ele)\n",
    "    \n",
    "        ele = ele.replace('<id>','').replace('</id>','')\n",
    "    \n",
    "        #ele = int(ele)\n",
    "    \n",
    "        refs[k] = ele\n",
    "        \n",
    "    for pmid in refs:\n",
    "        \n",
    "        cite_dict[ID].append(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cite_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cite_dict for later hierarchy construction\n",
    "import json\n",
    "\n",
    "#with open('NAc_CiteDict.json', 'w') as fp:\n",
    "#    json.dump(cite_dict, fp)\n",
    "    \n",
    "#with open('NAc_CiteDict.json', 'r') as fp:\n",
    "#    cite_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cite_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times each article is cited\n",
    "\n",
    "cite_cnt = {}\n",
    "\n",
    "for key in cite_dict:\n",
    "    \n",
    "    for value in cite_dict[key]:\n",
    "        \n",
    "        #value = value.lower()\n",
    "        #value = value.replace()\n",
    "        \n",
    "        if value in cite_cnt.keys():\n",
    "            \n",
    "            cite_cnt[value] += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            cite_cnt[value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep keys with over 'n' value count\n",
    "\n",
    "cited_papers = {key:val for key, val in cite_cnt.items() if val > 3}\n",
    "\n",
    "abc = dict(sorted(cited_papers.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: cite_cnt contains PMIDs for papers not in the 1000 paper call\n",
    "print(len(cite_cnt))\n",
    "print(len(cited_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop through each article\n",
    "# append the article PMID, author last name, year pub'd, article title, journal name to a DATAFRAME\n",
    "\n",
    "id_list2 = list(cited_papers.keys())\n",
    "\n",
    "paper_df = pd.DataFrame(columns = ['pmid','author','year','title','journal'])\n",
    "\n",
    "for k,ID in enumerate(id_list2):\n",
    "    \n",
    "    paper = fetch_details(ID)\n",
    "    \n",
    "    if paper['PubmedArticle'] == []:\n",
    "        \n",
    "        paper_df.loc[k] = ['nan','nan','nan','book','nan']\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        yr = 'None'\n",
    "\n",
    "        if 'DateCompleted' in paper['PubmedArticle'][0]['MedlineCitation']:\n",
    "\n",
    "            yr = paper['PubmedArticle'][0]['MedlineCitation']['DateCompleted']['Year']\n",
    "\n",
    "        ti = paper['PubmedArticle'][0]['MedlineCitation']['Article'].get('ArticleTitle','None')\n",
    "        \n",
    "        au = 'None'\n",
    "        \n",
    "        if 'AuthorList' in paper['PubmedArticle'][0]['MedlineCitation']['Article']:\n",
    "\n",
    "            au = paper['PubmedArticle'][0]['MedlineCitation']['Article']['AuthorList'][0].get('LastName','None')\n",
    "\n",
    "        jo = paper['PubmedArticle'][0]['MedlineCitation']['Article']['Journal'].get('Title','None')\n",
    "\n",
    "        paper_df.loc[k] = [ID, au, yr, ti, jo]\n",
    "\n",
    "        time.sleep(0.7)  # delays url request for n seconds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['PubmedArticle'][0]['MedlineCitation']['Article'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paper_df.shape)\n",
    "paper_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cite_cnt for each pmid in the data frame\n",
    "\n",
    "paper_df['citedByNof1000'] = pd.Series(np.zeros([len(id_list2),]), index=paper_df.index)\n",
    "\n",
    "for k in range(len(paper_df)):\n",
    "    \n",
    "    if paper_df['pmid'][k] in cite_cnt.keys():\n",
    "        \n",
    "        paper_df['citedByNof1000'][k] = cite_cnt[paper_df['pmid'][k]]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper1_df = paper_df.sort_values(['citedByNof1000'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paper1_df.shape)\n",
    "paper1_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper1_df.to_csv('pubmed_NAc_top1000_Jan6.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list3 = list(cited_papers.keys())\n",
    "\n",
    "print(len(id_list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.Entrez as Entrez\n",
    "#from Bio.Entrez import efetch\n",
    "\n",
    "def get_abstract(pmid):\n",
    "    \n",
    "    Entrez.email = 'cepeders@ncsu.edu'\n",
    "    handle = Entrez.efetch(db='pubmed', id=pmid, retmode='text', rettype='abstract')\n",
    "    \n",
    "    txt = handle.read().strip().split('\\n\\n')\n",
    "    \n",
    "    longest = 0\n",
    "    copyright_idx = False\n",
    "\n",
    "    for n,sect in enumerate(txt):\n",
    "\n",
    "        if len(sect) > len(txt[longest]):\n",
    "\n",
    "            longest = n\n",
    "\n",
    "        if \"Copyright\" in sect:\n",
    "\n",
    "            copyright_idx = n\n",
    "            \n",
    "    #print(longest)\n",
    "    #print(copyright_idx)\n",
    "    #print('\\n')\n",
    "\n",
    "    if longest == (copyright_idx - 1):  \n",
    "        # if the longest string is also the string before the string containing 'Copyright'\n",
    "\n",
    "        abstract = txt[longest].replace('\\n',' ')\n",
    "        \n",
    "    elif copyright_idx == False:\n",
    "        \n",
    "        abstract = txt[longest].replace('\\n',' ')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if copyright_idx != False and longest != (copyright_idx - 1):\n",
    "            \n",
    "            abstract = txt[copyright_idx-1].replace('\\n',' ')\n",
    "\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abz_dict = {}\n",
    "\n",
    "for pmid in id_list3:\n",
    "    \n",
    "    tmp = get_abstract(pmid)\n",
    "    \n",
    "    abz_dict[pmid] = tmp\n",
    "    \n",
    "    time.sleep(0.8)\n",
    "    \n",
    "    if len(abz_dict.keys())%100 == 0:\n",
    "        print(len(abz_dict.keys()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the abz_dict for later NLP analysis\n",
    "import json\n",
    "\n",
    "#with open('NAcTopCited_AbzDict.json', 'w') as fp:\n",
    "#    json.dump(abz_dict, fp)\n",
    "    \n",
    "#with open('NAc_AbzDict.json', 'r') as fp:\n",
    "#    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cite_cnt dict to find how many times each abstract in abz_dict has been cited\n",
    "abz_cited = {}\n",
    "\n",
    "for key in abz_dict.keys():\n",
    "    \n",
    "    if key in cite_cnt.keys():\n",
    "        \n",
    "        abz_cited[key] = cite_cnt[key]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        abz_cited[key] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abz_cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the abz_cited for later NLP analysis\n",
    "import json\n",
    "\n",
    "#with open('NAcTopCited_AbzCited.json', 'w') as fp:\n",
    "#    json.dump(abz_cited, fp)\n",
    "    \n",
    "#with open('NAc_AbzDict.json', 'r') as fp:\n",
    "#    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary key for each article's PMID, and appeand values of keywords that are included for key PMID\n",
    "\n",
    "keyword_dict = {}\n",
    "\n",
    "for ID in id_list:\n",
    "    \n",
    "    keyword_dict[ID] = []\n",
    "    \n",
    "    paper = fetch_details(ID)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    #lengo = len(paper['PubmedArticle'][0]['MedlineCitation']['MeshHeadingList'])\n",
    "    \n",
    "    if paper['PubmedArticle'][0]['MedlineCitation']['KeywordList'] != []:\n",
    "        \n",
    "        lengo = len(paper['PubmedArticle'][0]['MedlineCitation']['KeywordList'][0])\n",
    "        \n",
    "        for k in range(lengo):\n",
    "        \n",
    "            #tempword = paper['PubmedArticle'][0]['MedlineCitation']['MeshHeadingList'][k]['DescriptorName'][:]\n",
    "            tempword = paper['PubmedArticle'][0]['MedlineCitation']['KeywordList'][0][k][:]\n",
    "        \n",
    "            keyword_dict[ID].append(tempword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keyword_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the frequency of each keyword\n",
    "\n",
    "value_cnt = {}\n",
    "\n",
    "for key in keyword_dict:\n",
    "    \n",
    "    for value in keyword_dict[key]:\n",
    "        \n",
    "        value = value.lower()\n",
    "        #value = value.replace()\n",
    "        \n",
    "        if value in value_cnt.keys():\n",
    "            \n",
    "            value_cnt[value] += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            value_cnt[value] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep keys with over 1 value count\n",
    "\n",
    "repeat_words = {key:val for key, val in value_cnt.items() if val > 1}\n",
    "\n",
    "abc = dict(sorted(repeat_words.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
